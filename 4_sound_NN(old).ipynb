{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pathlib\n",
    "import time\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch as torch\n",
    "#device = \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "torch.cuda.is_available() True\n",
      "torch.cuda.device_count() 1\n",
      "torch.cuda.current_device() 0\n",
      "torch.cuda.device(0) <torch.cuda.device object at 0x000001BF08397EC0>\n",
      "torch.cuda.get_device_name(0) NVIDIA GeForce RTX 4070 Ti\n",
      "torch.cuda.get_device_capability() (8, 9)\n",
      "torch.cuda.is_initialized() True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print('torch.cuda.is_available()', torch.cuda.is_available())\n",
    "print('torch.cuda.device_count()', torch.cuda.device_count())\n",
    "print('torch.cuda.current_device()', torch.cuda.current_device())\n",
    "print('torch.cuda.device(0)', torch.cuda.device(0))\n",
    "print('torch.cuda.get_device_name(0)', torch.cuda.get_device_name(0))\n",
    "print('torch.cuda.get_device_capability()', torch.cuda.get_device_capability())\n",
    "print('torch.cuda.is_initialized()', torch.cuda.is_initialized())\n",
    "#print('torch.cuda.temperature()', torch.cuda.temperature(device=None))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOUND_EDA_FOLDER = pathlib.Path().resolve()\n",
    "\n",
    "TRAIN_FOLDER = os.path.join(SOUND_EDA_FOLDER, 'train_folder')\n",
    "if not os.path.isdir(TRAIN_FOLDER):\n",
    "   os.makedirs(TRAIN_FOLDER)\n",
    "\n",
    "VALIDATION_FOLDER = os.path.join(SOUND_EDA_FOLDER, 'validation_folder')\n",
    "if not os.path.isdir(VALIDATION_FOLDER):\n",
    "   os.makedirs(VALIDATION_FOLDER)\n",
    "\n",
    "TEST_FOLDER = os.path.join(SOUND_EDA_FOLDER, 'test_folder')\n",
    "if not os.path.isdir(TEST_FOLDER):\n",
    "   os.makedirs(TEST_FOLDER)\n",
    "\n",
    "COMMON_FILES_FOLDER = os.path.join(SOUND_EDA_FOLDER, 'common_files_folder')\n",
    "if not os.path.isdir(COMMON_FILES_FOLDER):\n",
    "   os.makedirs(COMMON_FILES_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_TRAIN_AUDIOTRACKS = 64727\n",
    "NUMBER_OF_VALIDATION_AUDIOTRACKS = 6798\n",
    "NUMBER_OF_TEST_AUDIOTRACKS = 3081\n",
    "\n",
    "FOLDER_SIZE = 2048        # each folder contains spectrogramms of up to 2048 audiotracks\n",
    "\n",
    "NUMBER_OF_TRAIN_FOLDERS = NUMBER_OF_TRAIN_AUDIOTRACKS // FOLDER_SIZE + 1\n",
    "NUMBER_OF_VALIDATION_FOLDERS = NUMBER_OF_VALIDATION_AUDIOTRACKS // FOLDER_SIZE + 1\n",
    "NUMBER_OF_TEST_FOLDERS = NUMBER_OF_TEST_AUDIOTRACKS // FOLDER_SIZE + 1\n",
    "\n",
    "FRAME_LENGTH = 2048\n",
    "HOP_LENGTH = 512\n",
    "TIME_CUT_SIZE = 176 # this is number of frames equal to 4 seconds (1 sec = 44 frames)\n",
    "\n",
    "LONG_DATATYPE_BYTES = 4\n",
    "\n",
    "DOUBLE_DATATYPE_BYTES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(ConvModel, self).__init__()\n",
    "\n",
    "        self.conv_1 = torch.nn.Conv2d(kernel_size=3, in_channels=1, out_channels=32, stride=1, padding=1)\n",
    "        #self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.maxpool_1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv_2 = torch.nn.Conv2d(kernel_size=3, in_channels=32, out_channels=64, stride=1, padding=1)\n",
    "        #self.bn2 = torch.nn.BatchNorm2d(64)\n",
    "        self.maxpool_2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv_3 = torch.nn.Conv2d(kernel_size=3, in_channels=64, out_channels=128, stride=1, padding=1)\n",
    "        #self.bn3 = torch.nn.BatchNorm2d(128)\n",
    "        self.maxpool_3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.lin_1 = torch.nn.Linear(in_features=128*128*22, out_features=256)\n",
    "        self.lin_2 = torch.nn.Linear(in_features=256, out_features=num_classes)\n",
    "\n",
    "        self.dropout_conv = torch.nn.Dropout(p=0.1)\n",
    "        self.dropout_lin = torch.nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = self.maxpool_1(self.relu(self.bn1(self.conv_1(x))))    #ask gemini\n",
    "        x = self.maxpool_1(self.relu(self.conv_1(x))) # (batch_size, 1, 1024, 176) -> (batch_size, 32, 512, 88)\n",
    "        x = self.dropout_conv(x)\n",
    "        x = self.maxpool_2(self.relu(self.conv_2(x))) # (batch_size, 32, 512, 88) -> (batch_size, 64, 256, 44)\n",
    "        x = self.maxpool_3(self.relu(self.conv_3(x))) # (batch_size, 64, 256, 44) -> (batch_size, 128, 128, 22)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 128, 128, 22) -> (batch_size, 128*128*22)\n",
    "\n",
    "        x = self.relu(self.lin_1(x))  # (batch_size, 128*128*22) -> (batch_size, 256)\n",
    "        x = self.dropout_lin(x)\n",
    "        x = self.lin_2(x) # (batch_size, 256) -> (batch_size, 12)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, spectrogramm_dataset_folder_path):\n",
    "\n",
    "        self.spectrogramm_dataset_folder_path = spectrogramm_dataset_folder_path\n",
    "        self.general_file_path = os.path.join(spectrogramm_dataset_folder_path, 'general_file')\n",
    "        self.FOLDER_SIZE = 2048\n",
    "        self.LONG_DATATYPE_BYTES = 4\n",
    "        self.DOUBLE_DATATYPE_BYTES = 8\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # to read audiotrack\n",
    "        # 1) choose right folder. Each folder contains spectrogramm of 2048 spectrogramms\n",
    "        # so tracks 3,567,2047 will be in 1st folder, 2048,4095 will be in 2nd folder and so on\n",
    "        # i-th folder name is os.path.join(TRAIN_FOLDER, f'spectrogramms_{i*FOLDER_SIZE}-{(i+1)*FOLDER_SIZE-1}')\n",
    "        # 1) read file os.path.join(SUPERB_RESULTS_FOLDER, f'log_energy_spectrogramm_superb_v0_array_binary_i') where i is index of file (1st number)\n",
    "        # 2) read chunks of bytes starting from byte given by 4th number - this is .seek() argument in spectrogramm file\n",
    "        # 3) read doubles, which amount is equal to timeframes, and repeat this for each frequencyframe\n",
    "\n",
    "\n",
    "        \n",
    "        folder_index = idx//self.FOLDER_SIZE\n",
    "\n",
    "\n",
    "        current_folder_path = os.path.join(self.spectrogramm_dataset_folder_path, f'spectrogramms_{folder_index*self.FOLDER_SIZE}-{(folder_index+1)*self.FOLDER_SIZE-1}')\n",
    "        current_file_path = os.path.join(current_folder_path, f'log_energy_spectrogramm_superb_array_binary_{idx}')\n",
    "\n",
    "        with open(current_file_path, 'rb') as infile_current:\n",
    "\n",
    "            # read label first\n",
    "            chunk = infile_current.read(self.LONG_DATATYPE_BYTES)\n",
    "            label_of_current_track = struct.unpack(\"L\", chunk)[0]\n",
    "            label_of_current_track = torch.tensor(label_of_current_track)\n",
    "\n",
    "            # Читаем форму спектрограммы\n",
    "            shape_bytes = infile_current.read(8) # 8 байт для двух unsigned long\n",
    "            shape = struct.unpack('LL', shape_bytes)\n",
    "\n",
    "            #read spectrogramm\n",
    "            data_bytes = infile_current.read()\n",
    "\n",
    "        spectrogram = np.frombuffer(data_bytes, dtype=np.float64).reshape(shape)\n",
    "        spectrogram = torch.from_numpy(spectrogram.copy()).unsqueeze(0)\n",
    "        \n",
    "        return spectrogram, label_of_current_track\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(os.path.getsize(self.general_file_path)/(5*LONG_DATATYPE_BYTES))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SoundDataset(spectrogramm_dataset_folder_path=TRAIN_FOLDER)\n",
    "validation_dataset = SoundDataset(spectrogramm_dataset_folder_path=VALIDATION_FOLDER)\n",
    "test_dataset = SoundDataset(spectrogramm_dataset_folder_path=TEST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))\n\u001b[0;32m      2\u001b[0m some_spectrogramm, some_label \u001b[38;5;241m=\u001b[39m train_dataset[\u001b[38;5;241m14896\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrogramm type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(some_spectrogramm)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mspectrogramm shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msome_spectrogramm\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mspectrogramm:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msome_spectrogramm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "some_spectrogramm, some_label = train_dataset[14896]\n",
    "print(f'spectrogramm type: {type(some_spectrogramm)},\\nspectrogramm shape: {some_spectrogramm.size()},\\nspectrogramm:\\n{some_spectrogramm}')\n",
    "print(f'label type: {type(some_label)},\\nlabel: {some_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 10**(-150)\n",
    "lr = 10**(-3)\n",
    "batch_size = 64\n",
    "\n",
    "model = ConvModel()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)  #, num_workers=8, pin_memory=True\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "number_of_train_batches = len(train_dataset) // batch_size\n",
    "number_of_test_batches = len(test_dataset) // batch_size\n",
    "\n",
    "num_train_loops = len(train_dataloader)*batch_size\n",
    "num_test_loops = len(test_dataloader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7a2921aad84aa9b36f40e5caf7b2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcd4aa1222e412f924fe5f51eb39e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m train_true_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, target \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     10\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\superb\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\superb\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\superb\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m, in \u001b[0;36mSoundDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     39\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m infile_current\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDOUBLE_DATATYPE_BYTES)\n\u001b[0;32m     40\u001b[0m             decoded_number \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, chunk)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 42\u001b[0m             read_spectrogramm[frequencyframe][timeframe] \u001b[38;5;241m=\u001b[39m decoded_number          \n\u001b[0;32m     43\u001b[0m     infile_current\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     46\u001b[0m read_spectrogramm \u001b[38;5;241m=\u001b[39m read_spectrogramm\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_labels = []\n",
    "    train_true_labels = []\n",
    "\n",
    "    for X, target in tqdm(train_dataloader, leave=False):\n",
    "        \n",
    "        X = X.to(device).float()\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(X)\n",
    "        prediction_labels = preds.argmax(axis=1)    #preds.shape is (batch, numclasses). thats why axis=1\n",
    "        loss_value = loss_fn(preds, target)\n",
    "\n",
    "        train_labels += prediction_labels.detach().cpu().numpy().tolist()\n",
    "        train_true_labels += target.detach().cpu().numpy().tolist()\n",
    "        # detach - перестаем считать градиент\n",
    "        # cpu - перемещаем на ЦПУ\n",
    "        # numpy - переводим тензор в np.array\n",
    "        # tolist - переводим np.array в лист\n",
    "\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss = train_loss + loss_value.item()\n",
    "    \n",
    "    # simple metrics calculations\n",
    "    train_loss = train_loss / number_of_train_batches\n",
    "\n",
    "    train_labels=np.array(train_labels)\n",
    "    train_true_labels=np.array(train_true_labels)\n",
    "    \n",
    "    accuracy_score = np.sum(train_labels == train_true_labels) / len(train_labels)\n",
    "    \n",
    "    print('TRAIN: epoch = ', i, 'loss = ', train_loss, 'accuracy = ', accuracy_score)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # без подсчета градиентов!!!\n",
    "        test_loss = 0\n",
    "        test_labels = []\n",
    "        test_true_labels = []\n",
    "        \n",
    "        for X, target in tqdm(test_dataloader, leave=False):\n",
    "            X = X.to(device).float()\n",
    "            target = target.to(device)\n",
    "            preds = model(X)\n",
    "            \n",
    "            prediction_labels = preds.argmax(axis=1)\n",
    "            loss_value = loss_fn(preds, target)\n",
    "            \n",
    "            test_labels += prediction_labels.detach().cpu().numpy().tolist()\n",
    "            test_true_labels += target.detach().cpu().numpy().tolist()\n",
    "\n",
    "            test_loss = test_loss + loss_value.item()\n",
    "        \n",
    "        test_loss = test_loss / number_of_test_batches\n",
    "        \n",
    "        test_labels=np.array(test_labels)\n",
    "        test_true_labels=np.array(test_true_labels)\n",
    "\n",
    "        accuracy_score = np.sum(test_labels == test_true_labels) / len(test_labels)\n",
    "        \n",
    "        print( 'TEST: epoch = ', i , 'loss = ', test_loss , 'accuracy = ', accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
